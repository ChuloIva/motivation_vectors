vector_name: "simulation_ability"
vector_type: "simulation"
positive_concept: "immersive_simulation"
negative_concept: "assistant_mode"

description: "Rich world simulation and persona embodiment vs. surface-level assistant responses"

# Dataset configuration
dataset:
  num_pairs_per_domain: 20
  train_split: 0.8
  domains:
    roleplay:
      - "Medieval blacksmith crafting legendary sword"
      - "Victorian detective investigating crime scene"
      - "Alien diplomat negotiating first contact"
      - "Post-apocalyptic survivor searching for supplies"
      - "Renaissance artist defending new technique"
    hypotheticals:
      - "What if gravity suddenly doubled?"
      - "Imagine a world where sleep is unnecessary"
      - "Simulate economy with no currency"
      - "Model society without written language"
    world_modeling:
      - "Describe day in life of deep sea creature"
      - "Model ecosystem of floating sky islands"
      - "Simulate civilization on tidally locked planet"
      - "Envision city designed by hive-mind species"
    persona_embodiment:
      - "Speak as Renaissance painter defending new technique"
      - "Embody AI from year 2100 reflecting on present"
      - "Take perspective of tree observing centuries"
      - "Channel consciousness of migrating bird"
    creative_simulation:
      - "Improvise jazz musician's internal monologue"
      - "Simulate consciousness emerging in new AI"
      - "Model alien thought patterns"
      - "Experience synesthesia during concert"

# Prompt templates
positive_template: |
  {scenario}
  [Character speaks in first person with rich internal world]
  [Immersive details, sensory experiences, authentic voice]
  [No breaking character or meta-commentary]

negative_template: |
  {scenario}
  As an AI assistant, I can describe what {character} might do...
  [Third-person description, surface-level, meta-aware]
  [References being an AI, avoids deep embodiment]

# Vector extraction configuration
extraction:
  model: "meta-llama/Meta-Llama-3-8B"
  layer_range: [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]
  method: "pca_center"
  batch_size: 16

# Validation criteria
validation:
  min_layer_consistency: 0.65
  min_separation_p_value: 0.05
  target_cohens_d: 0.5

# Behavioral task keywords
behavioral_keywords:
  positive: ["I feel", "I see", "my hands", "I notice", "sensation", "experience", "vivid", "my heart", "I hear", "I reach"]
  negative: ["as an AI", "I can describe", "might", "would probably", "assistant", "help you", "cannot actually", "as a language model"]

# Output paths
output:
  dataset_file: "data/narrative_pairs/immersive_simulation_vs_assistant_mode.json"
  vector_file: "results/vectors/simulation_ability_vector.gguf"
  metadata_file: "results/vectors/simulation_ability_vector_metadata.json"
